{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "configuration = tf.compat.v1.ConfigProto()\n",
    "configuration.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=configuration)\n",
    "\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.optimizers import SGD, Adam, schedules\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "folder = \"D:\\FARM_data\\Soil_Spectra_Label\"\n",
    "f = h5py.File(folder+'\\labeled_data.hdf5', 'r')\n",
    "reread = pd.read_hdf(folder+\"\\labeled_data.hdf5\", key='FR')\n",
    "countries = ['AT', 'BE', 'BG', 'CY', 'CZ', 'DE', 'DK', 'EE', 'EL', 'ES', 'HR', 'HU', 'IE', 'IT', 'LT', 'LU', 'LV', 'MT', 'NL', 'PL', 'PT', 'RO', 'SE', 'SI', 'SK', 'UK']\n",
    "for country in countries:\n",
    "    temppd = pd.read_hdf(folder+\"\\labeled_data.hdf5\", key=country)\n",
    "    reread = pd.concat((reread, temppd), ignore_index = True)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20559\n"
     ]
    }
   ],
   "source": [
    "folder1 = \"D:\\FARM_data\\LUCAS2015_topsoildata_20200323\"\n",
    "tempdf = pd.read_csv(folder1+\"\\LUCAS_Topsoil_2015_20200323.csv\", usecols=[\"Point_ID\", \"LC1_Desc\"])\n",
    "reread = pd.merge(reread, tempdf, on='Point_ID', how='left')\n",
    "\n",
    "all_landscapes = reread[\"LC1_Desc\"].unique()\n",
    "\n",
    "print(len(reread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19097\n"
     ]
    }
   ],
   "source": [
    "filtered_df = pd.DataFrame(columns=reread.columns)\n",
    "\n",
    "for landscape in all_landscapes:\n",
    "    temppd = reread.loc[reread['LC1_Desc'] == landscape]\n",
    "    Q1 = temppd['OC'].quantile(0.25)\n",
    "    Q3 = temppd['OC'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    temppd = temppd[temppd['OC'] < Q3 + IQR * 1.5]\n",
    "    temppd = temppd[temppd['OC'] > Q1 - IQR * 1.5]\n",
    "    filtered_df = filtered_df.append(temppd)\n",
    "\n",
    "reread = filtered_df\n",
    "filtered_df = None\n",
    "print(len(reread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Point_ID</th>\n",
       "      <th>OC</th>\n",
       "      <th>NUTS_0</th>\n",
       "      <th>OC_state</th>\n",
       "      <th>spectogram</th>\n",
       "      <th>LC1_Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37802434</td>\n",
       "      <td>77.4</td>\n",
       "      <td>FR</td>\n",
       "      <td>60-80</td>\n",
       "      <td>[[[57, 86, 140], [57, 86, 140], [57, 86, 140],...</td>\n",
       "      <td>Grassland without tree/shrub cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38342416</td>\n",
       "      <td>26.9</td>\n",
       "      <td>FR</td>\n",
       "      <td>20-40</td>\n",
       "      <td>[[[66, 65, 134], [66, 65, 134], [66, 65, 134],...</td>\n",
       "      <td>Grassland without tree/shrub cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>37742430</td>\n",
       "      <td>60.7</td>\n",
       "      <td>FR</td>\n",
       "      <td>60-80</td>\n",
       "      <td>[[[55, 91, 141], [55, 91, 141], [55, 91, 141],...</td>\n",
       "      <td>Grassland without tree/shrub cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>38022434</td>\n",
       "      <td>61.4</td>\n",
       "      <td>FR</td>\n",
       "      <td>60-80</td>\n",
       "      <td>[[[63, 71, 136], [63, 71, 136], [63, 71, 136],...</td>\n",
       "      <td>Grassland without tree/shrub cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>38122428</td>\n",
       "      <td>85.6</td>\n",
       "      <td>FR</td>\n",
       "      <td>80-100</td>\n",
       "      <td>[[[61, 78, 138], [61, 78, 138], [61, 78, 138],...</td>\n",
       "      <td>Grassland without tree/shrub cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14569</th>\n",
       "      <td>39683304</td>\n",
       "      <td>21.5</td>\n",
       "      <td>NL</td>\n",
       "      <td>20-40</td>\n",
       "      <td>[[[65, 66, 135], [65, 66, 135], [65, 66, 135],...</td>\n",
       "      <td>Floriculture and ornamental plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14588</th>\n",
       "      <td>40343302</td>\n",
       "      <td>14.7</td>\n",
       "      <td>NL</td>\n",
       "      <td>0-20</td>\n",
       "      <td>[[[62, 73, 137], [62, 73, 137], [62, 73, 137],...</td>\n",
       "      <td>Floriculture and ornamental plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14593</th>\n",
       "      <td>40363308</td>\n",
       "      <td>13.6</td>\n",
       "      <td>NL</td>\n",
       "      <td>0-20</td>\n",
       "      <td>[[[64, 70, 136], [64, 70, 136], [64, 70, 136],...</td>\n",
       "      <td>Floriculture and ornamental plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14711</th>\n",
       "      <td>51123106</td>\n",
       "      <td>29.1</td>\n",
       "      <td>PL</td>\n",
       "      <td>20-40</td>\n",
       "      <td>[[[59, 82, 139], [59, 82, 139], [59, 82, 139],...</td>\n",
       "      <td>Floriculture and ornamental plants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19892</th>\n",
       "      <td>35743822</td>\n",
       "      <td>24.9</td>\n",
       "      <td>UK</td>\n",
       "      <td>20-40</td>\n",
       "      <td>[[[52, 97, 141], [52, 97, 141], [52, 97, 141],...</td>\n",
       "      <td>Floriculture and ornamental plants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19097 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Point_ID    OC NUTS_0 OC_state  \\\n",
       "3      37802434  77.4     FR    60-80   \n",
       "5      38342416  26.9     FR    20-40   \n",
       "12     37742430  60.7     FR    60-80   \n",
       "22     38022434  61.4     FR    60-80   \n",
       "27     38122428  85.6     FR   80-100   \n",
       "...         ...   ...    ...      ...   \n",
       "14569  39683304  21.5     NL    20-40   \n",
       "14588  40343302  14.7     NL     0-20   \n",
       "14593  40363308  13.6     NL     0-20   \n",
       "14711  51123106  29.1     PL    20-40   \n",
       "19892  35743822  24.9     UK    20-40   \n",
       "\n",
       "                                              spectogram  \\\n",
       "3      [[[57, 86, 140], [57, 86, 140], [57, 86, 140],...   \n",
       "5      [[[66, 65, 134], [66, 65, 134], [66, 65, 134],...   \n",
       "12     [[[55, 91, 141], [55, 91, 141], [55, 91, 141],...   \n",
       "22     [[[63, 71, 136], [63, 71, 136], [63, 71, 136],...   \n",
       "27     [[[61, 78, 138], [61, 78, 138], [61, 78, 138],...   \n",
       "...                                                  ...   \n",
       "14569  [[[65, 66, 135], [65, 66, 135], [65, 66, 135],...   \n",
       "14588  [[[62, 73, 137], [62, 73, 137], [62, 73, 137],...   \n",
       "14593  [[[64, 70, 136], [64, 70, 136], [64, 70, 136],...   \n",
       "14711  [[[59, 82, 139], [59, 82, 139], [59, 82, 139],...   \n",
       "19892  [[[52, 97, 141], [52, 97, 141], [52, 97, 141],...   \n",
       "\n",
       "                                 LC1_Desc  \n",
       "3      Grassland without tree/shrub cover  \n",
       "5      Grassland without tree/shrub cover  \n",
       "12     Grassland without tree/shrub cover  \n",
       "22     Grassland without tree/shrub cover  \n",
       "27     Grassland without tree/shrub cover  \n",
       "...                                   ...  \n",
       "14569  Floriculture and ornamental plants  \n",
       "14588  Floriculture and ornamental plants  \n",
       "14593  Floriculture and ornamental plants  \n",
       "14711  Floriculture and ornamental plants  \n",
       "19892  Floriculture and ornamental plants  \n",
       "\n",
       "[19097 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 = reread['OC'].quantile(0.25)\n",
    "# Q3 = reread['OC'].quantile(0.75)\n",
    "# IQR = Q3 - Q1\n",
    "# print(Q1, Q3, IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reread = reread[reread['OC'] < Q3 + IQR * 3]\n",
    "# reread = reread[reread['OC'] > Q1 - IQR * 3]\n",
    "# # reread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reread = reread.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['AT', 'BE', 'BG', 'CY', 'CZ', 'DE', 'DK', 'EE', 'EL', 'ES', 'FR', 'HR', 'HU', 'IE', 'IT', 'LT', 'LU', 'LV', 'MT', 'NL', 'PL', 'PT', 'RO', 'SE', 'SI', 'SK', 'UK']>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(reread['spectogram'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = reread['OC_state'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = None\n",
    "# y = None\n",
    "# reread = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4775, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14322, 22)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14322, 217, 335, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14322, 22)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential() # Linear stacking of layers\n",
    "\n",
    "# # Convolution Layer 1\n",
    "# model.add(Conv2D(16,(5,5),input_shape=(217,335,3),\n",
    "#     padding='same',activation='relu',\n",
    "#     kernel_constraint=MaxNorm(3)))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "# # Convolution Layer 2\n",
    "# model.add(Conv2D(8,(7,7), activation='relu', padding='same', kernel_constraint=MaxNorm(3)))\n",
    "# model.add(MaxPooling2D(pool_size=(9,9)))\n",
    "# model.add(Flatten())\n",
    "\n",
    "# # Fully Connected Layer 3\n",
    "# model.add(Dense(512,activation='relu',kernel_constraint=MaxNorm(3)))\n",
    "\n",
    "# # Fully Connected Layer 4\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(len(y[1]), activation='relu'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', metrics='accuracy', optimizer='adam') # categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=Sequential() # Linear stacking of layers\n",
    "# model.add(Conv2D(16, (7, 7), strides=(2, 2), padding=\"valid\", kernel_regularizer=reg,\n",
    "#             input_shape=(217,335,3)))\n",
    "#         # here we stack two CONV layers on top of each other where\n",
    "#         # each layerswill learn a total of 32 (3x3) filters\n",
    "# model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "#             kernel_initializer=init, kernel_regularizer=reg))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=chanDim))\n",
    "# model.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\",\n",
    "#             kernel_initializer=init, kernel_regularizer=reg))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=chanDim))\n",
    "# model.add(Dropout(0.25))\n",
    "#         # stack two more CONV layers, keeping the size of each filter\n",
    "#         # as 3x3 but increasing to 64 total learned filters\n",
    "# model.add(Conv2D(64, (3, 3), padding=\"same\",\n",
    "#             kernel_initializer=init, kernel_regularizer=reg))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=chanDim))\n",
    "# model.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\",\n",
    "#             kernel_initializer=init, kernel_regularizer=reg))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=chanDim))\n",
    "# model.add(Dropout(0.25))\n",
    "#         # increase the number of filters again, this time to 128\n",
    "# model.add(Conv2D(128, (3, 3), padding=\"same\",\n",
    "#             kernel_initializer=init, kernel_regularizer=reg))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=chanDim))\n",
    "# model.add(Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\",\n",
    "#             kernel_initializer=init, kernel_regularizer=reg))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=chanDim))\n",
    "# model.add(Dropout(0.25))\n",
    "# # fully-connected layer\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(512, kernel_initializer=init))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.5))\n",
    "#         # softmax classifier\n",
    "# model.add(Dense(len(y[1])))\n",
    "# model.add(Activation(\"softmax\"))\n",
    "# model.compile(loss='categorical_crossentropy', metrics='accuracy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=l2(0.0005)\n",
    "init=\"he_normal\"\n",
    "chanDim = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (7, 7), strides=(2, 2), padding=\"valid\",\n",
    "            kernel_initializer=init, kernel_regularizer=reg,\n",
    "            input_shape=(217,335,3)))\n",
    "\n",
    "# here we stack two CONV layers on top of each other where\n",
    "# each layerswill learn a total of 32 (3x3) filters\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "    kernel_initializer=init, kernel_regularizer=reg))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\",\n",
    "    kernel_initializer=init, kernel_regularizer=reg))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# stack two more CONV layers, keeping the size of each filter\n",
    "# as 3x3 but increasing to 64 total learned filters\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\",\n",
    "    kernel_initializer=init, kernel_regularizer=reg))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\",\n",
    "    kernel_initializer=init, kernel_regularizer=reg))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# increase the number of filters again, this time to 128\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\",\n",
    "    kernel_initializer=init, kernel_regularizer=reg))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\",\n",
    "    kernel_initializer=init, kernel_regularizer=reg))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# fully-connected layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_initializer=init))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# softmax classifier\n",
    "model.add(Dense(len(y[1])))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics='accuracy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 106, 165, 16)      2368      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 106, 165, 32)      4640      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 106, 165, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 106, 165, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 53, 83, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 53, 83, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 53, 83, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 53, 83, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 53, 83, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 53, 83, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 53, 83, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 27, 42, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 27, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 27, 42, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 27, 42, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 27, 42, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 27, 42, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 27, 42, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 21, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 21, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 37632)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               19268096  \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 22)                11286     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 22)                0         \n",
      "=================================================================\n",
      "Total params: 19,576,342\n",
      "Trainable params: 19,574,422\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "224/224 [==============================] - 48s 142ms/step - loss: 3.4173 - accuracy: 0.3353\n",
      "Epoch 2/10\n",
      "224/224 [==============================] - 29s 131ms/step - loss: 1.7380 - accuracy: 0.5555\n",
      "Epoch 3/10\n",
      "224/224 [==============================] - 30s 133ms/step - loss: 1.5177 - accuracy: 0.5839\n",
      "Epoch 4/10\n",
      "224/224 [==============================] - 30s 133ms/step - loss: 1.4682 - accuracy: 0.5940\n",
      "Epoch 5/10\n",
      "224/224 [==============================] - 31s 137ms/step - loss: 1.3330 - accuracy: 0.6154\n",
      "Epoch 6/10\n",
      "224/224 [==============================] - 31s 136ms/step - loss: 1.2645 - accuracy: 0.6249\n",
      "Epoch 7/10\n",
      "224/224 [==============================] - 30s 136ms/step - loss: 1.2006 - accuracy: 0.6398\n",
      "Epoch 8/10\n",
      "224/224 [==============================] - 30s 134ms/step - loss: 1.1721 - accuracy: 0.6380\n",
      "Epoch 9/10\n",
      "224/224 [==============================] - 30s 136ms/step - loss: 1.1491 - accuracy: 0.6329\n",
      "Epoch 10/10\n",
      "224/224 [==============================] - 30s 133ms/step - loss: 1.1186 - accuracy: 0.6444\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                batch_size=64,\n",
    "                epochs=10,\n",
    "                verbose=1,\n",
    "                shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 4s 24ms/step - loss: 1.1299 - accuracy: 0.6467\n",
      "Test score: 1.1298558712005615\n",
      "Test accuracy: 0.6467015743255615\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is our input data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: put here code that reads an array from above and prints a spectogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input data consists of 217x335x3 arrays. Which represent the rgb values of every pixel in a spectrogram. That spectrogram is created with spectral data from satellites.\n",
    "\n",
    "So now we have to research what hypothetically is a good model to train on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filters\n",
    "In this [source](https://datascience.stackexchange.com/questions/55545/in-cnn-why-do-we-increase-the-number-of-filters-in-deeper-convolution-layers-fo) you can see why we should start with lower amount of data filters and build that amount up in following layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in this [source](https://www.sicara.ai/blog/2019-10-31-convolutional-layer-convolution-kernel#:~:text=A%20common%20choice%20is%20to,%3A%203%2C%201%20by%20color.) that the most commenly used kernel sizes are 3x3 and 5x5. About half way on this page you can see that a 3x3 kernel size gives an higher accuracy.\n",
    "\n",
    "So lets start with 3x3 and if that doesn't really work. We can always try a 5x5 kernel size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strides\n",
    "[Here](https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/) is being said that you could actually use 2x2 for the strides instead of using MaxPooling. Also in the source there is being referenced to a paper that using strided convolution may actually be better than using pooling layers and can increase accuracy.\n",
    "\n",
    "So we'll try 2x2 strides and use no max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Padding\n",
    "Its prob better to use padding source [here](https://stats.stackexchange.com/questions/246512/convolutional-layers-to-pad-or-not-to-pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg=l2(0.0009)\n",
    "# init=\"he_normal\"\n",
    "# chanDim = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def root_mean_squared_error(y_true, y_pred):\n",
    "#         return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg=l2(0.0005)\n",
    "# init=\"he_normal\"\n",
    "# chanDim = -1\n",
    "\n",
    "# # Conv2D Layer 1\n",
    "# cnn = Sequential()\n",
    "# cnn.add(Conv2D(16, (3, 3), strides=(2, 2), padding=\"valid\", kernel_regularizer=reg, kernel_initializer=init,\n",
    "#             input_shape=(217,335,3)))\n",
    "# cnn.add(Activation(\"relu\"))\n",
    "\n",
    "# # Conv2D Layer 2\n",
    "# cnn.add(Conv2D(32, (3, 3), strides=(2, 2), padding=\"same\", kernel_regularizer=reg))\n",
    "# cnn.add(Activation(\"relu\"))\n",
    "# cnn.add(BatchNormalization())\n",
    "# cnn.add(Dropout(0.2))\n",
    "\n",
    "# # Conv2D Layer 3\n",
    "# cnn.add(Conv2D(64, (3, 3), strides=(2, 2), padding=\"same\", kernel_regularizer=reg))\n",
    "# cnn.add(Activation(\"relu\"))\n",
    "# cnn.add(BatchNormalization())\n",
    "# cnn.add(Dropout(0.2))\n",
    "\n",
    "# # Conv2D Layer 4\n",
    "# cnn.add(Conv2D(128, (3, 3), strides=(2, 2), padding=\"same\", kernel_regularizer=reg))\n",
    "# cnn.add(Activation(\"relu\"))\n",
    "# cnn.add(BatchNormalization())\n",
    "# cnn.add(Dropout(0.2))\n",
    "# cnn.add(Flatten())\n",
    "\n",
    "# # Fully connected layer 1\n",
    "# cnn.add(Dense(194))\n",
    "# cnn.add(Activation(\"relu\"))\n",
    "# cnn.add(BatchNormalization())\n",
    "# cnn.add(Dropout(0.2))\n",
    "\n",
    "# # Fully connected layer 2\n",
    "# cnn.add(Dense(len(y[1])))\n",
    "# cnn.add(Dropout(0.5))\n",
    "# cnn.add(Activation(\"relu\"))\n",
    "# cnn.compile(loss='categorical_crossentropy', metrics='accuracy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = cnn.fit(X_train, y_train,\n",
    "#                 batch_size=32,\n",
    "#                 epochs=10,\n",
    "#                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = cnn.evaluate(X_test, y_test)\n",
    "# print('Test score:', score[0])\n",
    "# print('Test mse:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
